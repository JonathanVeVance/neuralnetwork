{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers.activfunc import ReLu, sigmoid\n",
    "from helpers.lossfunc import sum_squares, cross_entropy\n",
    "# from optimizer import SGD, ..., optimizer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "activfunc_dict = {\n",
    "    'relu': ReLu, 'sigmoid': sigmoid\n",
    "}\n",
    "\n",
    "lossfunc_dict = {\n",
    "    'sumsquares': sum_squares, 'crossentropy': cross_entropy\n",
    "}\n",
    "\n",
    "# optimizer_dict = {\n",
    "#     'sgd': SGD, 'minibatchgd': MiniBatchGD, ... \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class neuralnetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.W = []\n",
    "        self.Z = []\n",
    "        self.Y = []\n",
    "        self.Wgrad = None\n",
    "        self.nlayers = 0\n",
    "        self.activations = []\n",
    "        self.prev_layer_neurons = None\n",
    "        \n",
    "    def add_layer(self, num_neurons, activation):\n",
    "        if self.nlayers == 0:\n",
    "            self.W.append(None)\n",
    "        else:\n",
    "            weights = np.random.rand(num_neurons, self.prev_layer_neurons + 1)\n",
    "            self.W.append(weights)\n",
    "        self.activations.append(activation.lower())\n",
    "        self.prev_layer_neurons = num_neurons\n",
    "        self.nlayers += 1\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        current_x = inputs\n",
    "        np.insert(current_x, 0, 1, axis = 0)\n",
    "        self.Y.append(current_x)\n",
    "        for k in range(nlayers):\n",
    "            z = (np.matmul(self.W[k], current_x.T)).T\n",
    "            Z.append(z)\n",
    "            \n",
    "            sigma = activfunc_dict[self.activations[k]]\n",
    "            y = sigma.forward(z)\n",
    "            self.Y.append(y)\n",
    "            current_x = y\n",
    "            np.insert(current_x, 0, 1, axis = 0)\n",
    "                        \n",
    "        return y\n",
    "        \n",
    "    def backward(self, op_gradient):\n",
    "        # Assuming op_gradient = row vector (convention)\n",
    "        current_grad = op_gradient\n",
    "        for k in range(nlayers, -1, -1): \n",
    "            sigma = activfunc_dict[self.activations[k - 1]]\n",
    "            gradDz = np.matmul(current_grad, sigma.backward(self.Z[k - 1]))\n",
    "            gradzw = np.matmul(np.ones(np.shape(W[k - 1])[0]), self.Y[k - 1])\n",
    "            self.Wgrad[k - 1] = np.matmul(gradDz, gradzw)\n",
    "            current_grad = np.matmul(gradDz, self.W[k - 1])\n",
    "    \n",
    "    def clear_outputs(self):\n",
    "        self.Z = []\n",
    "        self.Y = []\n",
    "        \n",
    "    def train_network(self, X_train, Y_train, method, loss_function, eta = 0.001):\n",
    "        \n",
    "        input_size = np.shape(X_train)[1]\n",
    "        layer1_size = np.shape(self.W[1])[1]\n",
    "        self.W[0] = np.random.rand(layer1_size, input_size + 1)\n",
    "        self.Wgrad = np.zeros(np.shape(self.W))\n",
    "        lossfunction = lossfunc_dict[loss_function.lower()]\n",
    "        update_rule = optimizer_dict[method.lower()]       \n",
    "        update_rule(self, X_train, Y_train, lossfunction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
